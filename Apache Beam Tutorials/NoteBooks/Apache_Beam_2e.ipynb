{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Composite Transform\n",
        "\n",
        "-\tTransforms can have a nested structure, where a complex transform performs multiple simpler transforms (such as more than one ParDo, Combine, GroupByKey, or even other composite transforms). These transforms are called composite transforms.\n",
        "-\tNesting multiple transforms inside a single composite transform can make your code more modular and easier to understand\n",
        "\n",
        "#Creating a composite transform:\n",
        "-\tTo create your own composite transform, create a subclass of the PTransform class and override the expand method to specify the actual processing logic.\n",
        "-\tThe transforms can include core transforms, composite transforms, or the transforms included in the Beam SDK libraries.\n",
        "- The following code sample shows how to declare a PTransform that accepts a PCollection of Strings for input, and outputs a PCollection of Integers:\n",
        "\n",
        "  ```\n",
        "  class ComputeWordLengths(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "      # Transform logic goes here.\n",
        "      return pcoll | beam.Map(lambda x: len(x))\n",
        "  ```\n",
        "\n",
        "\n",
        "-\tThe expand method is where you add the processing logic for the PTransform. Your override of expand must accept the appropriate type of input PCollection as a parameter, and specify the output PCollection as the return value.\n",
        "-\tYou can include as many transforms as you want. These transforms can include core transforms, composite transforms, or the transforms included in the Beam SDK libraries.\n",
        "-\tYour composite transform’s parameters and return value must match the initial input type and final return type for the entire transform, even if the transform’s intermediate data changes type multiple times.\n",
        "\n"
      ],
      "metadata": {
        "id": "8X0Fas4nV53_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "-K89wYTWXDdy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using normal transformation like\n",
        "  - Map\n",
        "  - Filter\n",
        "  - CombinePerKey\n",
        "\n",
        "For three different operations and it includes more code, memory space and time as well."
      ],
      "metadata": {
        "id": "MVwhQrtGXjaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitRow(element):\n",
        "  return element.split(',')\n",
        "\n",
        "def filter_on_count(element):\n",
        "  name, count = element\n",
        "  if count > 30:\n",
        "    return element\n",
        "\n",
        "def format_output(element):\n",
        "  name, count = element\n",
        "  return (name.encode('ascii'),str(count),'Experienced employee')"
      ],
      "metadata": {
        "id": "6ugJVUPZX642"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read Data\">> beam.io.ReadFromText(\"/content/sample_data/dept_data.txt\")\n",
        "      | \"Split\">> beam.Map(splitRow)\n",
        "  )\n",
        "  account_persons = (\n",
        "      input\n",
        "      | \"Get only Accnt Dept Person\" >> beam.Filter(lambda x : x[3]=='Accounts')\n",
        "      | \"Pair each accnt person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | \"Combine and Sum\" >> beam.CombinePerKey(sum)\n",
        "      | \"count filter accounts\" >>beam.Filter(filter_on_count)\n",
        "      | 'Regular accounts employee' >> beam.Map(format_output)\n",
        "      | 'Write results for account' >> beam.io.WriteToText('/content/sample_data/Account_People.txt')\n",
        "  )\n",
        "  hr_persons = (\n",
        "      input\n",
        "      | \"Get only HR Dept Person\" >> beam.Filter(lambda x : x[3]=='HR')\n",
        "      | \"Pair each hr person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | \"Combine and Sum hr\" >> beam.CombinePerKey(sum)\n",
        "      | \"count filter hr\" >>beam.Filter(filter_on_count)\n",
        "      | 'Regular hr employee' >> beam.Map(format_output)\n",
        "      | 'Write results for hr' >> beam.io.WriteToText('/content/sample_data/HR_People.txt')\n",
        "  )\n",
        "  finance_persons = (\n",
        "      input\n",
        "      | \"Get only Finance Dept Person\" >> beam.Filter(lambda x : x[3]=='Finance')\n",
        "      | \"Pair each finance person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | \"Combine and Sum fin\" >> beam.CombinePerKey(sum)\n",
        "      | \"count filter finops\" >>beam.Filter(filter_on_count)\n",
        "      | 'Regular finance employee' >> beam.Map(format_output)\n",
        "      | 'Write results for finance' >> beam.io.WriteToText('/content/sample_data/Finance_People.txt')\n",
        "      #| beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THpEqTP1Xh99",
        "outputId": "6696b9c4-d8bf-4a78-a881-a9cf8f2eb24a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data/Finance_People.txt-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Composite Transforms\n",
        "\n",
        "- In above PTransforms we can notice CombinePerKey,Filter and Map are used in all three collections repeatedly.\n",
        "\n",
        "- Instead of calling them separtely we create a composite transform combining of those three transformations and call them in our pipeline."
      ],
      "metadata": {
        "id": "CI50W1ulatb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransform(beam.PTransform):\n",
        "\n",
        "  def expand(self, input_coll):\n",
        "\n",
        "    a = (\n",
        "        input_coll\n",
        "                       | 'Group and sum1' >> beam.CombinePerKey(sum)\n",
        "                       | 'count filter accounts' >> beam.Filter(filter_on_count)\n",
        "                       | 'Regular accounts employee' >> beam.Map(format_output)\n",
        "\n",
        "    )\n",
        "    return a"
      ],
      "metadata": {
        "id": "-oA97_9-Yokr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read Data\">> beam.io.ReadFromText(\"/content/sample_data/dept_data.txt\")\n",
        "      | \"Split\">> beam.Map(splitRow)\n",
        "  )\n",
        "  account_persons = (\n",
        "      input\n",
        "      | \"Get only Accnt Dept Person\" >> beam.Filter(lambda x : x[3]=='Accounts')\n",
        "      | \"Pair each accnt person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | 'composite accounts' >> MyTransform()\n",
        "      | 'Write results for account' >> beam.io.WriteToText('/content/sample_data/Account_People.txt')\n",
        "  )\n",
        "  hr_persons = (\n",
        "      input\n",
        "      | \"Get only HR Dept Person\" >> beam.Filter(lambda x : x[3]=='HR')\n",
        "      | \"Pair each hr person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | 'composite hr' >> MyTransform()\n",
        "      | 'Write results for hr' >> beam.io.WriteToText('/content/sample_data/HR_People.txt')\n",
        "  )\n",
        "  finance_persons = (\n",
        "      input\n",
        "      | \"Get only Finance Dept Person\" >> beam.Filter(lambda x : x[3]=='Finance')\n",
        "      | \"Pair each finance person\" >> beam.Map(lambda x : (x[1],1))\n",
        "      | 'composite finance' >> MyTransform()\n",
        "      | 'Write results for finance' >> beam.io.WriteToText('/content/sample_data/Finance_People.txt')\n",
        "      #| beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm3j4XvwbpOP",
        "outputId": "e0adc0a4-6f4d-4104-f0b3-469acf20412b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 /content/sample_data/Account_People.txt-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqlCVB05b2IY",
        "outputId": "866a6234-cf5c-4e06-8a3f-3a351571641e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Marco', '31', 'Experienced employee')\n",
            "(b'Rebekah', '31', 'Experienced employee')\n",
            "(b'Itoe', '31', 'Experienced employee')\n",
            "(b'Edouard', '31', 'Experienced employee')\n",
            "(b'Kyle', '62', 'Experienced employee')\n",
            "(b'Kumiko', '31', 'Experienced employee')\n",
            "(b'Gaston', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 /content/sample_data/Finance_People.txt-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeMElk7PcKlu",
        "outputId": "b6deba5b-638d-4013-8a95-bb01a9ad914d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Kumiko', '31', 'Experienced employee')\n",
            "(b'Wendy', '31', 'Experienced employee')\n",
            "(b'Cristobal', '31', 'Experienced employee')\n",
            "(b'Erika', '31', 'Experienced employee')\n",
            "(b'Sebastien', '31', 'Experienced employee')\n",
            "(b'Valerie', '31', 'Experienced employee')\n",
            "(b'Dolly', '31', 'Experienced employee')\n",
            "(b'Emily', '31', 'Experienced employee')\n",
            "(b'Kaori', '31', 'Experienced employee')\n",
            "(b'Hitomi', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 /content/sample_data/HR_People.txt-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osf7e4thcQh4",
        "outputId": "f28d1e80-0257-4233-93e3-4c8aae91e125"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Beryl', '62', 'Experienced employee')\n",
            "(b'Olga', '31', 'Experienced employee')\n",
            "(b'Leslie', '31', 'Experienced employee')\n",
            "(b'Mindy', '31', 'Experienced employee')\n",
            "(b'Vicky', '31', 'Experienced employee')\n",
            "(b'Richard', '31', 'Experienced employee')\n",
            "(b'Kirk', '31', 'Experienced employee')\n",
            "(b'Kaori', '31', 'Experienced employee')\n",
            "(b'Oscar', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Side Input\n",
        "\n",
        "-\tA side input is an additional input that your DoFn can access each time it processes an element in the input PCollection.\n",
        "-\tIn addition to the main input PCollection, you can provide additional inputs to a ParDo transform in the form of side inputs.\n",
        "-\tSide inputs are useful if your ParDo needs to inject additional data when processing each element in the input PCollection, but the additional data needs to be determined at runtime (and not hard-coded).\n",
        "-\tSide inputs must be small in size and not as big as pcollection because it has to be kept in memory of each worker\n",
        "-\tSuch values might be determined by the input data, or depend on a different branch of your pipeline.\n"
      ],
      "metadata": {
        "id": "Y3mnpyMbd0ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#firstly read and get list of students we want to exclude\n",
        "input_list=list()\n",
        "with open('/content/sample_data/students_exclude.txt','r') as f:\n",
        "  for line in f:\n",
        "    input_list.append(line.rstrip())\n",
        "print(input_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOjaPgv-cU-C",
        "outputId": "5c2d383f-9648-4c0b-d89e-e040cf8a9bad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now create pipeline and read student_age file\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,input_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in input_list:\n",
        "      return [customer]\n",
        "\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read Data\">> beam.io.ReadFromText(\"/content/sample_data/Students_age.txt\")\n",
        "      | \"Split\">> beam.ParDo(SplitRow(),input_list)\n",
        "      | \"Write results\" >> beam.io.WriteToText('/content/sample_data/student_age_output.txt')\n",
        "  )"
      ],
      "metadata": {
        "id": "eLP6b_3OeaND"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 /content/sample_data/student_age_output.txt-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v8mm_W8fJCu",
        "outputId": "a2f6a2da-fa3f-426a-c1da-c2f67ff4362c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n",
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Side Outputs/ Additional Outputs\n",
        "  \n",
        "- While ParDo always produces a main output PCollection (as the return value from apply), you can also have your ParDo produce any number of additional output PCollections.\n",
        "- If you choose to have multiple outputs, your ParDo returns all of the output PCollections (including the main output) bundled together.\n"
      ],
      "metadata": {
        "id": "xXnIVzK6hk-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a side list by reading students_Exclude\n",
        "side_list = list()\n",
        "with open ('/content/sample_data/students_exclude.txt','r') as exclude_file:\n",
        "  for cust_id in exclude_file:\n",
        "    side_list.append(cust_id.rstrip())\n",
        "print(side_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp7q6WyXfa--",
        "outputId": "fb6efc7c-4371-414a-bdf0-ad2eb3225798"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,side_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in side_list:\n",
        "      return [customer]\n",
        "\n",
        "class ProcessCustomers(beam.DoFn):\n",
        "  def process(self,element,country,start_char):\n",
        "    if(element[2]==country):\n",
        "      yield  element\n",
        "    else:\n",
        "      yield  beam.pvalue.TaggedOutput('Other_student',element)\n",
        "    if(element[1].startswith('r')):\n",
        "       yield  beam.pvalue.TaggedOutput('Names_r',element)"
      ],
      "metadata": {
        "id": "NuFNWu6qiQFC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read Data\">> beam.io.ReadFromText(\"/content/sample_data/Students_age.txt\")\n",
        "      | \"Side input\" >> beam.ParDo(SplitRow(),side_list)\n",
        "      | \"Side Output\" >> beam.ParDo(ProcessCustomers(),'chn','r').with_outputs('Names_r','Other_student',main='Chennai_Cust')\n",
        "  )\n",
        "\n",
        "chennai_customers = p.Chennai_Cust\n",
        "other_cities_customers = p.Other_student\n",
        "customer_withname_r = p.Names_r\n",
        "\n",
        "chennai_customers | 'Write Chennai Students PCollection' >> beam.io.WriteToText(\"chennai\")\n",
        "other_cities_customers  | 'Write Students PCollection that lives in other cities' >> beam.io.WriteToText(\"students_other_cities\")\n",
        "customer_withname_r  | 'Write Students names with r PCollection' >> beam.io.WriteToText(\"customers_names_r\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "YwO2RChVh0eD",
        "outputId": "d9e2f8a0-2136-48d1-d1c4-20de2555e583"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Pipeline' object has no attribute 'Chennai_Cust'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-acf9dc79161b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mchennai_customers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChennai_Cust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mother_cities_customers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOther_student\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mcustomer_withname_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNames_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'Chennai_Cust'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6cmdqRKizrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}