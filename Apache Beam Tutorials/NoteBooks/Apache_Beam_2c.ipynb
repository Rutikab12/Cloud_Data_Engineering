{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GroupBy\n",
        "\n",
        "- while normal GroupBy takes a collection of elements and produces a grouped collection of elements, here key is dynamically created from elements."
      ],
      "metadata": {
        "id": "2amjBGh0utot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GroupBy normal grouping using\n",
        "import apache_beam as beam\n",
        "with beam.Pipeline() as pipeline:\n",
        "    input = (\n",
        "        pipeline\n",
        "        | beam.Create(\n",
        "            ['strawberry', 'raspberry', 'blueberry', 'blackberry', 'banana'])\n",
        "        | \"Grouping\" >> beam.GroupBy(lambda s: s[0])\n",
        "        | \"Print\" >> beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "d4qQ1B0SwbGu",
        "outputId": "dd9cfa3c-c30c-456b-e96e-8a71e196f34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('s', ['strawberry'])\n",
            "('r', ['raspberry'])\n",
            "('b', ['blueberry', 'blackberry', 'banana'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aggregation\n",
        "\n",
        "- Grouping is often used in conjunction with aggregation, and the aggregate_field method of the GroupBy transform can be used to accomplish this easily.\n",
        "- This method takes three parameters: the field (or expression) which to aggregate, the CombineFn (or associative callable) with which to aggregate by, and finally a field name in which to store the result."
      ],
      "metadata": {
        "id": "q7gxQjlMx971"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROCERY_LIST = [\n",
        "    beam.Row(recipe='pie', fruit='strawberry', quantity=3, unit_price=1.50),\n",
        "    beam.Row(recipe='pie', fruit='raspberry', quantity=1, unit_price=3.50),\n",
        "    beam.Row(recipe='pie', fruit='blackberry', quantity=1, unit_price=4.00),\n",
        "    beam.Row(recipe='pie', fruit='blueberry', quantity=1, unit_price=2.00),\n",
        "    beam.Row(recipe='muffin', fruit='blueberry', quantity=2, unit_price=2.00),\n",
        "    beam.Row(recipe='muffin', fruit='banana', quantity=3, unit_price=1.00),\n",
        "]"
      ],
      "metadata": {
        "id": "hMG1CfVYw-sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grouping using key\n",
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read List\" >> beam.Create(GROCERY_LIST)\n",
        "      | \"Grouping\" >> beam.GroupBy('recipe')\n",
        "      | \"Print Result\" >> beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kRYx1-1yOAw",
        "outputId": "26752df8-ec6c-40d2-f3e0-56f5c18f2b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('pie', [BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='pie', fruit='strawberry', quantity=3, unit_price=1.5), BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='pie', fruit='raspberry', quantity=1, unit_price=3.5), BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='pie', fruit='blackberry', quantity=1, unit_price=4.0), BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='pie', fruit='blueberry', quantity=1, unit_price=2.0)])\n",
            "('muffin', [BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='muffin', fruit='blueberry', quantity=2, unit_price=2.0), BeamSchema_85b7e927_0a2e_4283_8b59_bb1f053a7dd5(recipe='muffin', fruit='banana', quantity=3, unit_price=1.0)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grouping using aggregate function like sum\n",
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read List\" >> beam.Create(GROCERY_LIST)\n",
        "      #| \"Grouping\" >> beam.GroupBy('recipe').aggregate_field('quantity',sum,'total_quantity')\n",
        "      | \"Grouping\" >> beam.GroupBy('recipe').aggregate_field('quantity', sum, 'total_quantity').aggregate_field(lambda x: x.quantity * x.unit_price, sum, 'total_price')\n",
        "      | \"Print Result\" >> beam.Map(print)\n",
        "  )\n",
        "  grouped = (\n",
        "      p\n",
        "      | beam.Create(GROCERY_LIST)\n",
        "      | beam.GroupBy().aggregate_field(\n",
        "          'unit_price', min, 'min_price').aggregate_field(\n",
        "                  'unit_price', max, 'max_price')\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbU2uPe1ym6W",
        "outputId": "4cff9615-9fe0-4523-c93d-34ab62c53d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result(recipe='pie', total_quantity=6, total_price=14.0)\n",
            "Result(recipe='muffin', total_quantity=5, total_price=7.0)\n",
            "Result(min_price=1.0, max_price=4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GroupByKey\n",
        "\n",
        "- GroupByKey is a Beam transform for processing collections of key/value pairs.\n",
        "- It’s a parallel reduction operation, analogous to the Shuffle phase of a Map/Shuffle/Reduce-style algorithm.\n",
        "- The input to GroupByKey is a collection of key/value pairs that represents a multimap, where the collection contains multiple pairs that have the same key, but different values. Given such a collection, you use GroupByKey to collect all of the values associated with each unique key."
      ],
      "metadata": {
        "id": "czhYHDEu0Xby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Groupbykey\n",
        "records = [(\"vignesh\", [27, \"engineer\"]),\n",
        "(\"neethu\", [27, \"developer\"]),\n",
        "(\"farooqui\", [26, \"data analyst\"]),\n",
        "(\"sai\", [29, \"web developer\"]),\n",
        "(\"tinkle\", [28, \"fullstack developer\"]),\n",
        "(\"neethu\", 'Employed'),\n",
        "(\"sai\", 'Unemployed'),\n",
        "(\"tinkle\", 'Employed'),\n",
        "(\"farooqui\",'Employed'),\n",
        "(\"vignesh\", 'Unemployed')]"
      ],
      "metadata": {
        "id": "FQjZvBGWzOtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | \"Read List\" >> beam.Create(records)\n",
        "      | \"GroupByKey\" >> beam.GroupByKey()\n",
        "      #| \"Sorting and format\" >> beam.MapTuple(lambda k,vs: (k,sorted(vs)))\n",
        "      | \"Print Result\" >> beam.Map(print)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iupG9Rhs1IvG",
        "outputId": "c23bdfdd-b3a5-4be0-ba5a-072bf9918729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', [[27, 'engineer'], 'Unemployed'])\n",
            "('neethu', [[27, 'developer'], 'Employed'])\n",
            "('farooqui', [[26, 'data analyst'], 'Employed'])\n",
            "('sai', [[29, 'web developer'], 'Unemployed'])\n",
            "('tinkle', [[28, 'fullstack developer'], 'Employed'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CoGroupByKey\n",
        "\n",
        "- Aggregates all input elements by their key and allows downstream processing to consume all values associated with the key.\n",
        "- While GroupByKey performs this operation over a single input collection and thus a single type of input values.\n",
        "- CoGroupByKey operates over multiple input collections. As a result, the result for each key is a tuple of the values associated with that key in each input collection."
      ],
      "metadata": {
        "id": "Y6mwoicC2Hsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CoGroupByKey\n",
        "with beam.Pipeline() as pipeline:\n",
        "  student_pairs = pipeline | 'Create icons' >> beam.Create([\n",
        "      ('vignesh', 'bangalore'),\n",
        "      ('khaula', 'hyderabad'),\n",
        "      ('neethu', 'malapur'),\n",
        "      ('sai', 'chennai'),\n",
        "  ])\n",
        "\n",
        "  student_result = pipeline | 'Create durations' >> beam.Create([\n",
        "      ('vignesh', [15,\"FAIL\"]),\n",
        "      ('khaula', [99,\"PASS\"]),\n",
        "      ('neethu', [100,\"PASS\"]),\n",
        "      ('sai',[ 37,\"FAIL\"]),\n",
        "  ])\n",
        "\n",
        "  join_both = (\n",
        "      ({'student_pairs': student_pairs, 'student_result': student_result})\n",
        "      | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "      | 'Print' >> beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSm6j4xP1Xia",
        "outputId": "e15321bb-8039-47e2-b504-07fd614f9a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', {'student_pairs': ['bangalore'], 'student_result': [[15, 'FAIL']]})\n",
            "('khaula', {'student_pairs': ['hyderabad'], 'student_result': [[99, 'PASS']]})\n",
            "('neethu', {'student_pairs': ['malapur'], 'student_result': [[100, 'PASS']]})\n",
            "('sai', {'student_pairs': ['chennai'], 'student_result': [[37, 'FAIL']]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  student_pairs = pipeline | 'Create icons' >> beam.Create([\n",
        "      ('vignesh', 15),\n",
        "      ('khaula', 99),\n",
        "      ('neethu', 100),\n",
        "      ('sai', 37),\n",
        "  ])\n",
        "\n",
        "  student_result = pipeline | 'Create durations' >> beam.Create([\n",
        "      ('vignesh', \"FAIL\"),\n",
        "      ('khaula',\"PASS\"),\n",
        "      ('neethu',\"PASS\"),\n",
        "      ('sai', \"FAIL\"),\n",
        "  ])\n",
        "\n",
        "  plants = (({\n",
        "      'Marks': student_pairs, 'Result': student_result\n",
        "  })\n",
        "  | 'Merge' >> beam.CoGroupByKey()\n",
        "  | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASCNdkNW24a7",
        "outputId": "3593c947-27e7-416d-ea5f-07f0f9d2da73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', {'Marks': [15], 'Result': ['FAIL']})\n",
            "('khaula', {'Marks': [99], 'Result': ['PASS']})\n",
            "('neethu', {'Marks': [100], 'Result': ['PASS']})\n",
            "('sai', {'Marks': [37], 'Result': ['FAIL']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GroupIntoBatches:\n",
        "Batches the input into desired batch size."
      ],
      "metadata": {
        "id": "04rBcmF43Zc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  batches_with_keys = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('spring', '🍓'),\n",
        "          ('spring', '🥕'),\n",
        "          ('spring', '🍆'),\n",
        "          ('spring', '🍅'),\n",
        "          ('summer', '🥕'),\n",
        "          ('summer', '🍅'),\n",
        "          ('summer', '🌽'),\n",
        "          ('fall', '🥕'),\n",
        "          ('fall', '🍅'),\n",
        "          ('winter', '🍆'),\n",
        "      ])\n",
        "      | 'Group into batches'  >> beam.GroupIntoBatches(2)\n",
        "      | beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpyqY2793UrD",
        "outputId": "b4f9f60a-faf9-450d-d2ad-8d66f268eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', ['🍓', '🥕'])\n",
            "('spring', ['🍆', '🍅'])\n",
            "('summer', ['🥕', '🍅'])\n",
            "('fall', ['🥕', '🍅'])\n",
            "('summer', ['🌽'])\n",
            "('winter', ['🍆'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flatten()\n",
        "\n",
        "- It is a beam transform for PCollection objects that store the same data type.\n",
        "- Merges multiple PCollection objects into a single logical PCollection.\n",
        "- Kind of Union operation (takes duplicate)"
      ],
      "metadata": {
        "id": "gEYaSvI05Rpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input = (p\n",
        "           | \"first set\" >> beam.Create({1,2,3,4,5}))\n",
        "  input_2 = (p\n",
        "             | \"Second set\" >> beam.Create({6,7,8,9,1}))\n",
        "  result = (\n",
        "      (input, input_2)\n",
        "      | beam.Flatten()\n",
        "      | beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswWDHgR3kty",
        "outputId": "11b2235e-8bce-4397-f6d9-a78967171d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Partition:\n",
        "- Partition is a Beam transform for PCollection objects that store the same data type. It splits a single PCollection into a fixed number of smaller collections.\n",
        "\n",
        "- Partition divides the elements of a PCollection according to a partitioning function that you provide.\n",
        "\n",
        "- The partitioning function contains the logic that determines how to split up the elements of the input PCollection into each resulting partition PCollection.\n",
        "\n",
        "- The number of partitions must be determined at graph construction time.\n",
        "\n",
        "- Partition accepts a function that receives the number of partitions, and returns the index of the desired partition for the element. The number of partitions passed must be a positive integer, and it must return an integer in the range 0 to num_partitions-1."
      ],
      "metadata": {
        "id": "byvthM728Cc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Partition using udf\n",
        "def splitting_data(element,num_of_part):\n",
        "  return 0 if element%2==0 else 1\n",
        "\n",
        "number = {11,12,13,44,55,61,77,88,99}\n",
        "with beam.Pipeline() as p:\n",
        "  input = (\n",
        "      p\n",
        "      | beam.Create(number)\n",
        "      | \"Do Partitions\" >> beam.Partition(splitting_data,2)\n",
        "      #| \"Print Partitions\" >> beam.Map(print)\n",
        "  )\n",
        "input[0] | \"Printing first partition\" >> beam.io.WriteToText('first_partition')\n",
        "input[1] | \"Printing second partition\" >> beam.io.WriteToText('second_partition')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10kgqFB06ADc",
        "outputId": "36e60d4b-b8d5-4b20-9536-0ebfe5d70d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PCollection[[36]: Printing second partition/Write/WriteImpl/FinalizeWrite.None] at 0x7881e6d8c0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMO9gX-x9QDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}